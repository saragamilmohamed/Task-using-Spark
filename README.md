# Apache Spark Tasks Collection ðŸš€

This repository contains a collection of practical tasks and mini-projects implemented using **Apache Spark**. Each task is written in Jupyter Notebooks (`.ipynb`) and covers a specific core component of Spark, demonstrating hands-on experience with distributed computing and big data processing.

## ðŸ“š Contents

The notebooks are categorized as follows:

- ðŸ“¦ **RDD (Resilient Distributed Datasets)**  
  Explore the low-level API of Spark with transformations and actions on RDDs.

- ðŸ§  **Machine Learning (MLlib)**  
  Apply machine learning algorithms using Spark's MLlib for tasks like classification, regression, and clustering.

- ðŸ§® **DataFrame and SQL**  
  Use Spark DataFrames and SQL queries for structured data processing.

- ðŸ”— **GraphFrames**  
  Work with graph data using the GraphFrames library to perform graph computations.

- ðŸ“¡ **Structured Streaming**  
  Build real-time data pipelines using Spark Structured Streaming
